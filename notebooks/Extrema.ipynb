{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import argrelextrema\n",
    "import ccxt\n",
    "import pandas as pd\n",
    "import numba as nb\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.jit\n",
    "def create_target(df, long, method='polyfit', polyfit_var='close', pct=0.1):\n",
    "    if method == 'polyfit':\n",
    "\n",
    "        trend_list = []\n",
    "        slope_list = []\n",
    "        start_list = []\n",
    "        end_list = []\n",
    "\n",
    "        index_l = np.arange(long)\n",
    "        rolling_df = df[polyfit_var].rolling(window=long, min_periods=long)\n",
    "        for roll in rolling_df:\n",
    "            if len(roll) < long:\n",
    "                continue\n",
    "            slope_array = np.round(np.polyfit(index_l, roll.values, deg=1)[-2], decimals=8)\n",
    "            slope_list.append(slope_array)\n",
    "            trend_list.append(np.where(slope_array > 0, 1, np.where(slope_array == 0, 0, -1)).tolist())\n",
    "            start_list.append(roll.index[0])\n",
    "            end_list.append(roll.index[long-1])\n",
    "\n",
    "    y = pd.DataFrame({'trend': trend_list, 'slope': slope_list, 'start_windows': start_list, 'end_windows': end_list})\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjusted_sigmoid(x, k=0.5, x0=0):\n",
    "    \"\"\"\n",
    "    Adjusted sigmoid function to map values to the range [-1, 1].\n",
    "    k controls the steepness of the curve.\n",
    "    x0 is the midpoint of the sigmoid.\n",
    "    \"\"\"\n",
    "    return 2 / (1 + np.exp(-k * (x - x0))) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_1000_candles(market='ADA/USDT', tf='1h'):\n",
    "    ex = ccxt.binance()\n",
    "    ohlcv = ex.fetch_ohlcv(market, tf, limit=1001)  # Fetch one extra to ensure 1000 closed candles\n",
    "\n",
    "    # Build DataFrame\n",
    "    header = ['timestamp', 'open', 'high', 'low', 'close', 'volume']\n",
    "    ohlcv_df = pd.DataFrame(ohlcv, columns=header)\n",
    "    ohlcv_df['timestamp'] = pd.to_datetime(ohlcv_df['timestamp'], unit='ms', utc=True)\n",
    "    # ohlcv_df.set_index('timestamp', inplace=True)\n",
    "\n",
    "    # Remove the last row to ensure all candles are closed\n",
    "    ohlcv_df = ohlcv_df.iloc[:-1].copy()\n",
    "\n",
    "    return ohlcv_df\n",
    "\n",
    "# download_1000_candles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candles = download_1000_candles(market='BTC/USDT', tf='1h')\n",
    "candles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 6\n",
    "min_peaks = argrelextrema(\n",
    "\tcandles[\"low\"].values, np.less,\n",
    "\torder=kernel\n",
    ")\n",
    "max_peaks = argrelextrema(\n",
    "\tcandles[\"high\"].values, np.greater,\n",
    "\torder=kernel\n",
    ")\n",
    "\n",
    "candles[\"extrema\"] = 0\n",
    "\n",
    "for mp in min_peaks[0]:\n",
    "\tcandles.at[mp, \"extrema\"] = -1\n",
    "for mp in max_peaks[0]:\n",
    "\tcandles.at[mp, \"extrema\"] = 1\n",
    "\n",
    "candles['extrema'] = candles['extrema'].rolling(\n",
    "\twindow=3, win_type='gaussian', center=True).mean(std=0.5)\n",
    "\n",
    "candles['extrema'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candles['extrema'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candles['extrema'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import argrelextrema\n",
    "import scipy.stats as stats\n",
    "\n",
    "def extrema_analyze_candles(candles, kernel=6):\n",
    "    # Find peaks\n",
    "    min_peaks = argrelextrema(candles[\"low\"].values, np.less, order=kernel)[0]\n",
    "    max_peaks = argrelextrema(candles[\"high\"].values, np.greater, order=kernel)[0]\n",
    "\n",
    "    # Count peaks\n",
    "    num_low_peaks = len(min_peaks)\n",
    "    num_high_peaks = len(max_peaks)\n",
    "    total_peaks = num_low_peaks + num_high_peaks\n",
    "\n",
    "    # Prepare lists for data\n",
    "    distances = []\n",
    "    candles_between_peaks = []\n",
    "    distance_per_candle = []\n",
    "\n",
    "    for low_peak in min_peaks:\n",
    "        # Find the next high peak\n",
    "        next_high_peaks = max_peaks[max_peaks > low_peak]\n",
    "        if next_high_peaks.size > 0:\n",
    "            high_peak = next_high_peaks[0]\n",
    "            low_price = candles.at[low_peak, 'close']\n",
    "            high_price = candles.at[high_peak, 'close']\n",
    "            distance_percentage = ((high_price - low_price) / low_price) * 100\n",
    "            distances.append(distance_percentage)\n",
    "\n",
    "            # Calculate number of candles between peaks\n",
    "            num_candles = high_peak - low_peak\n",
    "            candles_between_peaks.append(num_candles)\n",
    "\n",
    "            # Calculate distance % per candle\n",
    "            if num_candles != 0:\n",
    "                distance_per_candle.append(distance_percentage / num_candles)\n",
    "            else:\n",
    "                distance_per_candle.append(0)\n",
    "\n",
    "    # Describe distances, candles between peaks, and distance per candle\n",
    "    distances_description = pd.Series(distances).describe()\n",
    "    candles_between_peaks_description = pd.Series(candles_between_peaks).describe()\n",
    "    distance_per_candle_description = pd.Series(distance_per_candle).describe()\n",
    "\n",
    "    print(f\"Low peaks: {num_low_peaks}\")\n",
    "    print(f\"High peaks: {num_high_peaks}\")\n",
    "    print(f\"Total peaks: {total_peaks}\")\n",
    "    print(f\"Distances (%): {distances_description}\")\n",
    "    print(f\"Candles between peaks: {candles_between_peaks_description}\")\n",
    "    # print(f\"Distance per candle (%): {distance_per_candle_description}\")\n",
    "\n",
    "    # Perform correlation analysis\n",
    "    if len(distances) > 1 and len(candles_between_peaks) > 1:  # Ensure there are enough data points\n",
    "        correlation, p_value = stats.pearsonr(candles_between_peaks, distances)\n",
    "\n",
    "        print(f\"Correlation between number of candles and return price: {correlation}\")\n",
    "        print(f\"P-value of the correlation: {p_value}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Not enough data points for correlation analysis.\")\n",
    "    # return num_low_peaks, num_high_peaks, total_peaks, distances_description, candles_between_peaks_description, distance_per_candle_description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrema_analyze_candles2(candles, kernel=6):\n",
    "    # Find peaks\n",
    "    min_peaks = argrelextrema(candles[\"low\"].values, np.less, order=kernel)[0]\n",
    "    max_peaks = argrelextrema(candles[\"high\"].values, np.greater, order=kernel)[0]\n",
    "\n",
    "    # Count peaks\n",
    "    num_low_peaks = len(min_peaks)\n",
    "    num_high_peaks = len(max_peaks)\n",
    "    total_peaks = num_low_peaks + num_high_peaks\n",
    "\n",
    "    # Prepare lists for upward data\n",
    "    distances_upward = []\n",
    "    candles_between_peaks_upward = []\n",
    "\n",
    "    # Prepare lists for downward data\n",
    "    distances_downward = []\n",
    "    candles_between_peaks_downward = []\n",
    "\n",
    "    # Calculate distances upward (low to high)\n",
    "    for low_peak in min_peaks:\n",
    "        next_high_peaks = max_peaks[max_peaks > low_peak]\n",
    "        if next_high_peaks.size > 0:\n",
    "            high_peak = next_high_peaks[0]\n",
    "            low_price = candles.at[low_peak, 'close']\n",
    "            high_price = candles.at[high_peak, 'close']\n",
    "            distance_upward = ((high_price - low_price) / low_price) * 100\n",
    "            distances_upward.append(distance_upward)\n",
    "            num_candles_upward = high_peak - low_peak\n",
    "            candles_between_peaks_upward.append(num_candles_upward)\n",
    "\n",
    "    # Calculate distances downward (high to low)\n",
    "    for high_peak in max_peaks:\n",
    "        next_low_peaks = min_peaks[min_peaks > high_peak]\n",
    "        if next_low_peaks.size > 0:\n",
    "            low_peak = next_low_peaks[0]\n",
    "            high_price = candles.at[high_peak, 'close']\n",
    "            low_price = candles.at[low_peak, 'close']\n",
    "            distance_downward = ((low_price - high_price) / high_price) * 100\n",
    "            distances_downward.append(distance_downward)\n",
    "            num_candles_downward = low_peak - high_peak\n",
    "            candles_between_peaks_downward.append(num_candles_downward)\n",
    "\n",
    "    # Describe upward data\n",
    "    distances_upward_description = pd.Series(distances_upward).describe()\n",
    "    candles_between_peaks_upward_description = pd.Series(candles_between_peaks_upward).describe()\n",
    "\n",
    "    # Describe downward data\n",
    "    distances_downward_description = pd.Series(distances_downward).describe()\n",
    "    candles_between_peaks_downward_description = pd.Series(candles_between_peaks_downward).describe()\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Low peaks: {num_low_peaks}, High peaks: {num_high_peaks}, Total peaks: {total_peaks}\")\n",
    "    print(f\"Upward Distances (%): {distances_upward_description}\")\n",
    "    print(f\"Candles Between Peaks Upward: {candles_between_peaks_upward_description}\")\n",
    "    print(f\"Downward Distances (%): {distances_downward_description}\")\n",
    "    print(f\"Candles Between Peaks Downward: {candles_between_peaks_downward_description}\")\n",
    "\n",
    "    # Perform correlation analysis for upward movement\n",
    "    if len(distances_upward) > 1 and len(candles_between_peaks_upward) > 1:\n",
    "        correlation_upward, p_value_upward = stats.pearsonr(candles_between_peaks_upward, distances_upward)\n",
    "        print(f\"Correlation between number of candles and return price (upward): {correlation_upward}, P-value: {p_value_upward}\")\n",
    "\n",
    "    # Perform correlation analysis for downward movement\n",
    "    if len(distances_downward) > 1 and len(candles_between_peaks_downward) > 1:\n",
    "        correlation_downward, p_value_downward = stats.pearsonr(candles_between_peaks_downward, distances_downward)\n",
    "        print(f\"Correlation between number of candles and return price (downward): {correlation_downward}, P-value: {p_value_downward}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Not enough data points for correlation analysis.\")\n",
    "\n",
    "    # Return the data for further analysis if needed\n",
    "    return {\n",
    "        \"upward\": {\n",
    "            \"num_low_peaks\": num_low_peaks,\n",
    "            \"num_high_peaks\": num_high_peaks,\n",
    "            \"total_peaks\": total_peaks,\n",
    "            \"distances\": distances_upward_description,\n",
    "            \"candles_between_peaks\": candles_between_peaks_upward_description,\n",
    "            \"correlation\": correlation_upward,\n",
    "            \"p_value\": p_value_upward\n",
    "        },\n",
    "        \"downward\": {\n",
    "            \"distances\": distances_downward_description,\n",
    "            \"candles_between_peaks\": candles_between_peaks_downward_description,\n",
    "            \"correlation\": correlation_downward,\n",
    "            \"p_value\": p_value_downward\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrema_analyze_candles3(candles, kernel=6):\n",
    "    # Find peaks\n",
    "    min_peaks = argrelextrema(candles[\"low\"].values, np.less, order=kernel)[0]\n",
    "    max_peaks = argrelextrema(candles[\"high\"].values, np.greater, order=kernel)[0]\n",
    "\n",
    "    # Prepare lists for upward and downward data\n",
    "    distances_upward = []\n",
    "    candles_between_peaks_upward = []\n",
    "    distances_downward = []\n",
    "    candles_between_peaks_downward = []\n",
    "\n",
    "    # Iterate over low peaks to find the next high peak\n",
    "    for low_peak in min_peaks:\n",
    "        next_high_peaks = max_peaks[max_peaks > low_peak]\n",
    "        if next_high_peaks.size > 0:\n",
    "            high_peak = next_high_peaks[0]\n",
    "            distance_percentage = ((candles.at[high_peak, 'close'] - candles.at[low_peak, 'close']) / candles.at[low_peak, 'close']) * 100\n",
    "            distances_upward.append(distance_percentage)\n",
    "            candles_between_peaks_upward.append(high_peak - low_peak)\n",
    "\n",
    "    # Iterate over high peaks to find the next low peak\n",
    "    for high_peak in max_peaks:\n",
    "        next_low_peaks = min_peaks[min_peaks > high_peak]\n",
    "        if next_low_peaks.size > 0:\n",
    "            low_peak = next_low_peaks[0]\n",
    "            distance_percentage = ((candles.at[low_peak, 'close'] - candles.at[high_peak, 'close']) / candles.at[high_peak, 'close']) * -100\n",
    "            distances_downward.append(distance_percentage)\n",
    "            candles_between_peaks_downward.append(low_peak - high_peak)\n",
    "\n",
    "    # Merge and describe the data\n",
    "    all_distances = distances_upward + distances_downward\n",
    "    all_candles_between_peaks = candles_between_peaks_upward + candles_between_peaks_downward\n",
    "    all_distances_description = pd.Series(all_distances).describe()\n",
    "    all_candles_between_peaks_description = pd.Series(all_candles_between_peaks).describe()\n",
    "\n",
    "    # Print merged results\n",
    "    print(f\"Merged Distances (%): {all_distances_description}\")\n",
    "    print(f\"Merged Candles Between Peaks: {all_candles_between_peaks_description}\")\n",
    "\n",
    "    # Return the merged data for further analysis if needed\n",
    "    # return {\n",
    "    #     \"merged_distances\": all_distances_description,\n",
    "    #     \"merged_candles_between_peaks\": all_candles_between_peaks_description\n",
    "    # }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low peaks: 53\n",
      "High peaks: 54\n",
      "Total peaks: 107\n",
      "Distances (%): count    52.000000\n",
      "mean      1.763008\n",
      "std       1.794914\n",
      "min      -1.162591\n",
      "25%       0.682252\n",
      "50%       1.234622\n",
      "75%       2.527502\n",
      "max       6.739049\n",
      "dtype: float64\n",
      "Candles between peaks: count    52.000000\n",
      "mean     11.019231\n",
      "std       7.306968\n",
      "min       1.000000\n",
      "25%       5.750000\n",
      "50%       9.500000\n",
      "75%      16.250000\n",
      "max      32.000000\n",
      "dtype: float64\n",
      "Correlation between number of candles and return price: 0.35286895459135464\n",
      "P-value of the correlation: 0.01029264997271907\n"
     ]
    }
   ],
   "source": [
    "extrema_analyze_candles(candles, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Distances (%): count    106.000000\n",
      "mean       1.553823\n",
      "std        1.604107\n",
      "min       -1.700418\n",
      "25%        0.621755\n",
      "50%        1.219966\n",
      "75%        2.156576\n",
      "max        6.739049\n",
      "dtype: float64\n",
      "Merged Candles Between Peaks: count    106.000000\n",
      "mean      10.424528\n",
      "std        7.179267\n",
      "min        1.000000\n",
      "25%        5.250000\n",
      "50%        8.000000\n",
      "75%       14.750000\n",
      "max       32.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "extrema_analyze_candles3(candles, 6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "freqtrade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
